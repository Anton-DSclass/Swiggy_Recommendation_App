Streamlit Code

---

# ğŸ½ï¸ Swiggy Restaurant Recommendation System

A **Machine Learningâ€“based restaurant recommendation system** built using **Python, Streamlit, and Scikit-learn**, inspired by Swiggy.
This app recommends restaurants based on **city, cuisine preference, minimum rating, cost, and delivery time** using a **content-based filtering approach**.

---

## ğŸš€ Features

* ğŸ™ï¸ **City-based filtering**
* ğŸ± **Cuisine-based recommendation**
* â­ **Minimum rating selection**
* ğŸ“Š **Similarity matching using ML**
* ğŸ”„ **Smart fallback logic** when data is limited
* ğŸ¨ **Custom Streamlit UI** with Swiggy-style theme
* âš¡ **Fast loading using caching**

---

## ğŸ§  Recommendation Logic (How it Works)

1. **User Inputs**

   * City
   * Cuisine
   * Minimum Rating
   * Number of Recommendations

2. **Filtering Steps**

   * City + Cuisine + Rating
   * If insufficient â†’ City + Rating
   * If still insufficient â†’ Global top-rated restaurants

3. **Machine Learning**

   * Uses **StandardScaler** for normalization
   * Applies **Nearest Neighbors (Cosine Similarity)**
   * Recommends similar restaurants based on:

     * Rating
     * Cost
     * Delivery Time

---

## ğŸ› ï¸ Tech Stack

| Category      | Tools                                 |
| ------------- | ------------------------------------- |
| Frontend      | Streamlit                             |
| Backend       | Python                                |
| ML            | Scikit-learn                          |
| Data Handling | Pandas                                |
| Styling       | HTML + CSS                            |
| Model         | Nearest Neighbors (Cosine Similarity) |

---

## ğŸ“‚ Project Structure

```
Project-04/
â”‚
â”œâ”€â”€ Streamlitapp/
â”‚   â”œâ”€â”€ app.py                  # Main Streamlit app
â”‚   â”œâ”€â”€ Cleaned.pkl             # Cleaned restaurant data
â”‚   â”œâ”€â”€ Encoded.pkl             # One-hot encoded features
â”‚   â”œâ”€â”€ Swiggy-logo.png         # App logo
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ data_cleaning.ipynb
â”‚   â”œâ”€â”€ feature_encoding.ipynb
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸ“¦ Installation & Setup

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/your-username/swiggy-recommendation-system.git
cd swiggy-recommendation-system
```

### 2ï¸âƒ£ Create Virtual Environment (Optional but Recommended)

```bash
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Run the Streamlit App

```bash
streamlit run app.py
```

---

## ğŸ“„ Dataset Description

### `Cleaned.pkl`

Contains:

* Restaurant Name
* City
* Cuisine
* Rating
* Cost
* Delivery Time

### `Encoded.pkl`

Contains:

* Numerical features
* One-hot encoded cuisines
* Used for similarity calculations

---

## ğŸ¯ Use Cases

* Food delivery platforms
* Recommendation systems projects
* Machine learning portfolios
* Academic final-year projects
* Viva & interview demonstrations

---

## ğŸ“¸ App Preview

> Swiggy-style UI with sidebar preferences and restaurant cards
> *(Add screenshots here if you want)*

---

## ğŸ”® Future Enhancements

* ğŸ” User login & personalization
* ğŸ—ºï¸ Location-based distance filtering
* ğŸ¤– Hybrid recommendation (content + collaborative)
* ğŸ“ˆ Popularity trends
* ğŸŒ Cloud deployment

---

## ğŸ™Œ Author

**Anton Sam**
ğŸ“§ *Add email if needed*
ğŸ’¼ *Machine Learning | Data Science | Python*

---

## â­ Acknowledgements

* Inspired by **Swiggy**
* Streamlit Community
* Scikit-learn Documentation

---
*****************************************************************************************************************************************************************************

Main Code

# ğŸ“Š Data Preprocessing, Feature Engineering & Clustering Pipeline

This module focuses on **cleaning raw restaurant data**, **preparing features for machine learning**, **performing clustering**, and **saving processed datasets** for downstream use in a **recommendation system and ML models**.

---

## ğŸ§© Overview

The goal of this pipeline is to:

* Clean noisy real-world data
* Remove irrelevant and redundant columns
* Prepare numerical & encoded features
* Apply **unsupervised clustering**
* Store optimized datasets for **Streamlit deployment**

---

## ğŸ› ï¸ Libraries Used

| Category         | Libraries                       |
| ---------------- | ------------------------------- |
| Data Handling    | `pandas`, `numpy`               |
| Visualization    | `matplotlib`, `seaborn`         |
| Statistics       | `scipy.stats`                   |
| Machine Learning | `scikit-learn`, `xgboost`       |
| Models           | Linear, Tree, Boosting, SVM, GP |
| Clustering       | `KMeans`                        |
| Serialization    | `pickle`                        |

---

## ğŸ§¹ Step 1: Data Cleaning

### âœ”ï¸ Remove Invalid Column Names

```python
df = df.loc[:, df.columns.notna()]
df = df.loc[:, df.columns.str.strip() != ""]
```

* Removes **empty** or **blank** column names
* Prevents pipeline failures

---

### âœ”ï¸ Remove Auto-Generated Columns

```python
df = df.loc[:, ~df.columns.str.contains('^Unnamed')]
```

* Eliminates unnecessary index columns from CSV imports

---

### âœ”ï¸ Remove Time-Range Columns

```python
df = df.loc[:, ~df.columns.str.contains("To|PM|Pm")]
```

* Removes time-based textual columns not useful for ML
* Ensures numeric-only feature space

---

### âœ”ï¸ Drop Non-ML Columns

```python
cols_to_remove = ["name", "lic_no", "link", "address", "menu"]
df.drop(columns=cols_to_remove, inplace=True)
```

These columns:

* Are **identifiers or text-heavy**
* Do not contribute to prediction or similarity

---

## ğŸ§  Step 2: Machine Learning Models Imported

This project supports **multiple regression models** for experimentation:

* Linear Regression
* Random Forest Regressor
* Gradient Boosting
* AdaBoost
* XGBoost
* Support Vector Regression (SVR)
* Gaussian Process Regressor

ğŸ“Œ *Models are imported for benchmarking and performance comparison.*

---

## ğŸ”§ Step 3: Feature Scaling & Pipelines

* **StandardScaler** used for normalization
* **OneHotEncoder** & **MultiLabelBinarizer** for categorical data
* **ColumnTransformer + Pipeline** for clean ML workflows

This ensures:

* Consistent preprocessing
* Reproducibility
* No data leakage

---

## ğŸ§© Step 4: Clustering (Unsupervised Learning)

### ğŸ”¹ KMeans Clustering

```python
k = 20
kmeans = KMeans(n_clusters=k, random_state=42)
df['cluster'] = kmeans.fit_predict(X)
```

âœ”ï¸ Groups similar restaurants based on numeric features
âœ”ï¸ Helps in:

* Restaurant segmentation
* Faster recommendations
* Exploratory analysis

---

### ğŸ“ Cluster Evaluation

```python
score = silhouette_score(X, df['cluster'])
```

**Silhouette Score** measures:

* How well each restaurant fits within its cluster
* Value close to **1 â†’ better clustering**

---

## ğŸ’¾ Step 5: Dataset Serialization (Pickle)

```python
cleaned.to_pickle("Cleaned.pkl")
encoded.to_pickle("Encoded.pkl")
```

### Why Pickle?

* Faster loading than CSV
* Preserves data types
* Ideal for Streamlit apps

---

## ğŸ“‚ Output Files

| File          | Description                           |
| ------------- | ------------------------------------- |
| `Cleaned.pkl` | Human-readable restaurant details     |
| `Encoded.pkl` | ML-ready numerical & encoded features |

These files are later used in:

* Recommendation engine
* Similarity calculations
* Streamlit deployment

---

## ğŸ”„ Workflow Summary

```
Raw Data
   â†“
Data Cleaning
   â†“
Feature Engineering
   â†“
Scaling & Encoding
   â†“
Clustering
   â†“
Pickle Serialization
   â†“
Streamlit App
```

---

## ğŸ¯ Use Cases

* Restaurant recommendation systems
* Customer segmentation
* ML portfolio projects
* Final year / capstone projects
* Interview & viva demonstrations

---

## ğŸ”® Future Enhancements

* Automatic optimal `k` selection
* Cluster visualization dashboard
* Hybrid recommendation system
* Model performance comparison UI

---

## ğŸ‘¨â€ğŸ’» Author

**Anton Sam**
Machine Learning | Data Science | Python





